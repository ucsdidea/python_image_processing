{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing with Python\n",
    "Part of the SWEET Workshop series presented by the [IDEA Student Center at UC San Diego](http://idea.ucsd.edu/).\n",
    "\n",
    "### Goals\n",
    "Learn the basics of image processing using Python, including:\n",
    "- importing images\n",
    "- displaying images\n",
    "- cropping images\n",
    "- indexing images (grayscale and color)\n",
    "- filtering images\n",
    "\n",
    "### Requirements\n",
    "- numpy\n",
    "- matplotlib\n",
    "- scipy\n",
    "- pillow\n",
    "- imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to load the required packages\n",
    "#\n",
    "# NOTE: recall that in the Intro to Python workshop we learned\n",
    "# that you can assign aliases to package names so you don't\n",
    "# have to type as much (e.g. \"np\" for \"numpy\")\n",
    "#\n",
    "\n",
    "# numpy for vector operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use scipy's ndimage for common image filters\n",
    "from scipy import ndimage\n",
    "\n",
    "# image file I/O\n",
    "import imageio\n",
    "\n",
    "# make backwards-compatible with Python 2.x\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importing images\n",
    "We'll start by loading images and get familiar with how image data is stored, indexed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread('imageio:camera.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `imageio.imread()` loads the image as a numpy array, so we\n",
    "# can check the image dimensions with numpy's `shape()` function\n",
    "print(np.shape(image))\n",
    "\n",
    "# NOTE: you can also call `shape` from the array directly\n",
    "#print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "print(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the range of values in the image (e.g. maximum and minimum values)?\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "What can you tell about the image so far? For example:\n",
    "- How many pixels wide and tall is the image?\n",
    "- Is the image greyscale or in color (i.e. does it have 1 or 3 color channels)?\n",
    "- Are there units associated with the image? Or some sort of range of values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Displaying images\n",
    "The next natural step is to display the image. For this, we'll use matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Does the image look \"correct\"? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try displaying the image with a different colormap.\n",
    "# \n",
    "# usage:\n",
    "#     plt.imshow(image, cmap=\"some_colormap\")\n",
    "#\n",
    "# example colormaps:\n",
    "# - \"Greys\"\n",
    "# - \"Blues\"\n",
    "# - \"cubehelix\"\n",
    "# - \"viridis\"\n",
    "# - \"plasma\"\n",
    "#\n",
    "# for more colormaps, see the matplotlib website:\n",
    "#\n",
    "#    http://matplotlib.org/users/colormaps.html\n",
    "#\n",
    "plt.imshow(image, cmap='???')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Notice anything about the colormaps?\n",
    "\n",
    "If it's not obvious, try adding a colorbar to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(???)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* In matplotlib, you can reverse the order of any colormap by appending ``_r`` to the end of the colormap's name. For example:\n",
    "- ``Greys_r`` = ``Greys`` with reverse order\n",
    "- ``viridis_r`` = ``viridis`` with reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out one of the reversed colormaps\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Indexing and cropping images\n",
    "Since the image is now represented as a numpy ndarray, we can use indexing to select specific portions of the image, thereby cropping the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first 250 rows and first 250 columns\n",
    "plt.imshow(image[:250, :250], cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Based on the above cropped image view, where is the origin (0, 0) of the image? Is it the bottom-left (like a normal plot) or the top-left? Why is this the case?\n",
    "\n",
    "*Hint:* How are the rows and columns of a matrix ordered in math?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try selecting the last 250 rows and last 250 columns (using negative indexing)\n",
    "plt.imshow(image[-???:, -???:], cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a last test, try selecting the top-right portion of the image\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Displaying color images\n",
    "Let's move onto color images, which besides from being more interesting to look at, can also provide additional useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and displaying color images works similarly to\n",
    "# grayscale images\n",
    "\n",
    "# an image of a Husky from reddit\n",
    "#\n",
    "# source: /u/rickydlam\n",
    "#     https://www.reddit.com/r/aww/comments/1lompf/reddit_maya_maya_derp_mayas_my_roommates_dog_but/\n",
    "#\n",
    "dog = imageio.imread(\"husky.jpg\")\n",
    "print(dog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "How is the additional color information represented (compared to a greyscale image)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can display the color image the same way as the grayscale\n",
    "plt.imshow(dog)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Notice that the image was displayed in full color, instead of with a colormap (as in the case of the grayscale image).\n",
    "\n",
    "This is because the grayscale image only had pixel intensities for one color channel (the gray channel), while the color image has three color channels (red, green, blue) and so matplotlib is able to display the \"real\" colors of the image (instead of just the pixel intensities).\n",
    "\n",
    "**NOTE:** All of the color examples today will be in the standard RGB colorspace. But images can be stored and displayed using other colorspaces (e.g. CMYK = cyan, magent, yellow, black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the color image is also just a numpy array, we can use indexing to select the color channels. Let's start by looking at the red color channel by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows and columns, but only the red color channel (channel index=0)\n",
    "dog_red = dog[:, :, 0]\n",
    "\n",
    "# display the image\n",
    "plt.imshow(???)\n",
    "plt.colorbar(label='Red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "How do we interpret the pixel values when we select only one of the color channels? And why do some of the \"non-red\" areas still show non-zero red values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to select the green and then blue color channels by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try displaying the green channel (channel index=1)\n",
    "dog_green = ???\n",
    "plt.imshow(???)\n",
    "plt.colorbar(label='Green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the blue channel (channel index=2)\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be difficult to tell the difference between the color channels separately. So let's try displaying the three color channels side-by-side as subfigures of the same main figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with 1 row and 3 columns\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# show the color channels separately\n",
    "cmap = 'Greys_r'\n",
    "ax[0].imshow(dog[:, :, ???], cmap=cmap)  # red\n",
    "ax[1].imshow(dog[:, :, ???], cmap=cmap)  # green\n",
    "ax[2].imshow(dog[:, :, ???], cmap=cmap)  # blue\n",
    "\n",
    "# add labels\n",
    "ax[0].set_title('Red')\n",
    "ax[1].set_title('Green')\n",
    "ax[2].set_title('Blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Is there a drastic difference in the pixel intensities between the color channels? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try an image with a clearer color contrast/segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "sensor = imageio.imread('sensor.jpg')\n",
    "\n",
    "# display it in full color\n",
    "plt.imshow(sensor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Will this image be \"easier\" to segment compared to the image of the husky? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, let's display the red color channel by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sensor[:, :, 0], cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's see how well a (very) naive segmentation method would work for selecting the red cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the regions of the image where the red channel is above a threshold\n",
    "sensor_red = np.copy(sensor[:, :, 0])\n",
    "sensor_red[sensor_red < 150] = 0.0\n",
    "\n",
    "# compare the naive segmentation with the original image\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "ax[0].imshow(sensor)\n",
    "ax[1].imshow(sensor[:, :, 0], cmap='Greys_r')\n",
    "ax[2].imshow(sensor_red, cmap='Greys_r')\n",
    "\n",
    "ax[0].set_title('Original')\n",
    "ax[1].set_title('Red channel')\n",
    "ax[2].set_title('Red threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "How well did the (very) naive method work? Can you think of any methods that may work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Filters\n",
    "Since an image is just a signal, we can apply filters (e.g. to remove \"noise\"). Aside from filtering to remove \"bad\" data, we can also apply filters to extract useful data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) Sobel filter\n",
    "We'll start by testing a Sobel filter on a greyscale image.\n",
    "\n",
    "**NOTE:** We're obviously glossing over the background (and math) of the Sobel filter. Instead, we're just trying to get a feeling for what the filter does (i.e. the \"what\", not the \"why\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original (greyscale) image, with a higher precision (32-bit integer)\n",
    "source_image = imageio.imread('imageio:camera.png').astype('int32')\n",
    "\n",
    "# apply the Sobel filter\n",
    "sx = ndimage.sobel(source_image, axis=0, mode='constant')  # x-axis\n",
    "sy = ndimage.sobel(source_image, axis=1, mode='constant')  # y-axis\n",
    "s = np.sqrt(sx ** 2 + sy ** 2)                             # magnitude\n",
    "filtered_image = s / np.max(filtered_image) * 255.0        # normalize the result\n",
    "\n",
    "# compare the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "cmap = 'Greys_r'\n",
    "ax[0].imshow(source_image, cmap=cmap)\n",
    "ax[1].imshow(filtered_image, cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Based on the results, what did the Sobel filter seem to do to the image? Where would a Sobel image therefore be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) Gaussian filters\n",
    "Next up we'll try out a Gaussian filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and then apply the filter\n",
    "source_image = imageio.imread('imageio:camera.png')\n",
    "filtered_image = ndimage.gaussian_filter(source_image, sigma=5)\n",
    "\n",
    "# compare the results\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "What did the Gaussian filter do to the image? And what is the effect of changing the sigma parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a (very naive) way of using the Gaussian filter to blur the background of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and then apply the filter\n",
    "source_image = imageio.imread('imageio:camera.png')\n",
    "filtered_image = ndimage.gaussian_filter(source_image, sigma=10)\n",
    "\n",
    "# combine the two images to simulate background blur\n",
    "combined_image = np.copy(filtered_image)\n",
    "x0, y0 = 50, 180\n",
    "dx, dy = 125, 125\n",
    "combined_image[x0:x0 + dx, y0:y0 + dx] = source_image[x0:x0 + dx, y0:y0 + dx]\n",
    "\n",
    "# compare the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "cmap = 'Greys_r'\n",
    "ax[0].imshow(source_image, cmap=cmap)\n",
    "ax[1].imshow(filtered_image, cmap=cmap)\n",
    "ax[2].imshow(combined_image, cmap=cmap)\n",
    "\n",
    "ax[0].set_title('Original')\n",
    "ax[1].set_title('Filtered')\n",
    "ax[2].set_title('Background blur')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "How could you improve our \"naive\" background blurring method? What other sort of information would be helpful in this case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
